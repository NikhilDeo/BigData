{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5 - People in a Room\n",
    "#### A K-Nearest Neighbor Algorithm Lab by Nikhil Deo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "This lab uses a k-nearest neighbor algorithm to predict whether or not there is a person in a room. The dataset includes certain factors about the room's environment including humidity, CO2, and light. This dataset was provided by Emma Anderson. This lab is regarding two questions: whether or not the number of nearest neighbors affects the accuracy and how valuable each attribute is to the accuracy of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def euclidianDistance(item1, item2, attributes):\n",
    "    distance = 0\n",
    "    for x in range(attributes-2):\n",
    "        distance+=(item1[x]-item2[x])**2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def getNeighbors(trainingset, test, k):\n",
    "    distances = []\n",
    "    length = len(test) - 1\n",
    "    for x in range(len(trainingset)):\n",
    "        dist = euclidianDistance(test, trainingset[x], length)\n",
    "        distances.append((trainingset[x], dist))\n",
    "#sort on distance, not datapoint    \n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "def getresponse(neighbors):\n",
    "    classvotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classvotes:\n",
    "            classvotes[response]+=1\n",
    "        else:\n",
    "            classvotes[response] = 1\n",
    "    sortedvotes = sorted(classvotes.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    return sortedvotes[0][0]\n",
    "\n",
    "def getaccuracy(testset, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testset)):\n",
    "        if testset[x][-1] == predictions[x]:\n",
    "            correct+=1\n",
    "    return (correct/float(len(testset)))*100.0\n",
    "\n",
    "def loadDataset(filename, split, trainingset, testset):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        del dataset[0]\n",
    "        for z in range(len(dataset)):\n",
    "            del dataset[z][0]\n",
    "            del dataset[z][0]\n",
    "        for x in range(1, len(dataset)-2):\n",
    "            for y in range(0, len(dataset[0])):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "            if random.random() < split:\n",
    "                trainingset.append(dataset[x])\n",
    "            else:\n",
    "                testset.append(dataset[x])\n",
    "                \n",
    "def main(k, dictionary):\n",
    "    trainingset = []\n",
    "    testset = []\n",
    "    split = 0.9\n",
    "    loadDataset('datatraining.txt', split, trainingset, testset)\n",
    "    predictions = []\n",
    "    for x in range(len(testset)):\n",
    "        neighbors = getNeighbors(trainingset, testset[x], k)\n",
    "        result = getresponse(neighbors)\n",
    "        predictions.append(result)\n",
    "#        print('Predictions:' + str(result) + 'Actual:' + str(testset[x][-1]))\n",
    "    accuracy = getaccuracy(testset, predictions)\n",
    "#    print(k, 'Accuracy:' + str(accuracy) + '%')\n",
    "    dictionary[\"k =\", k] = str(accuracy)\n",
    "\n",
    "accuracyList = {}\n",
    "for x in range(3, 10):\n",
    "    main(x, accuracyList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Does the value of 'k' change the accuracy of the algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.15458937198068\n",
      "('k =', 3)\n",
      "\n",
      "Dictionary accuracyList:\n",
      "('k =', 3) : 99.15458937198068\n",
      "('k =', 4) : 98.33729216152018\n",
      "('k =', 9) : 98.95697522816167\n",
      "('k =', 7) : 98.55421686746988\n",
      "('k =', 8) : 99.12935323383084\n",
      "('k =', 6) : 98.2843137254902\n",
      "('k =', 5) : 98.64532019704434\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for majorkey in accuracyList:\n",
    "    if float(accuracyList[majorkey]) > float(t):\n",
    "        t = accuracyList[majorkey]\n",
    "        l = majorkey\n",
    "\n",
    "print(t)\n",
    "print(l)\n",
    "print(\"\")\n",
    "print(\"Dictionary accuracyList:\")\n",
    "for x in accuracyList:\n",
    "    print(x, \":\", accuracyList[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "While there is variation between accuracy of the algorithm for various k-values, there is no trend. After running the code a number of times, I have found no value of 'k' that consistently makes the algoritm more accurate than the rest. The above code uses a dictionary containing the accuracy of the algorithm for 7 values of k and compares each to find the k-value that results in the most accurate algorithm. I found that essentially every time I ran the code, a different k-value would have the highest accuracy with no trend. Additionally, each value for k yilds a similar accuracy percentage. Every k-value returned an accuracy between 98% and 99.8%. This clearly indicates that the number of neighbors tested for does not make the algorithm any more or less accurate. It is also important to note that the accuracy percentage remains exceptionally high throughout with no k-value lowering the percentage to below 98% (that I've seen in my tests, at least).\n",
    "\n",
    "### Question 2: Can some attributes be removed while still having an accuracy greater than 90%? Which attribute seems to be the most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HumidityRatio': 96.86323713927227, 'Humidity': 98.57328145265889, 'CO2': 96.47058823529412, 'Light': 98.53658536585365}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def euclidianDistance(item1, item2, attributes):\n",
    "    distance = 0\n",
    "    for x in range(attributes-2):\n",
    "        distance+=(item1[x]-item2[x])**2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def getNeighbors(trainingset, test, k):\n",
    "    distances = []\n",
    "    length = len(test) - 1\n",
    "    for x in range(len(trainingset)):\n",
    "        dist = euclidianDistance(test, trainingset[x], length)\n",
    "        distances.append((trainingset[x], dist))\n",
    "#sort on distance, not datapoint    \n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "def getresponse(neighbors):\n",
    "    classvotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classvotes:\n",
    "            classvotes[response]+=1\n",
    "        else:\n",
    "            classvotes[response] = 1\n",
    "    sortedvotes = sorted(classvotes.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    return sortedvotes[0][0]\n",
    "\n",
    "def getaccuracy(testset, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testset)):\n",
    "        if testset[x][-1] == predictions[x]:\n",
    "            correct+=1\n",
    "    return (correct/float(len(testset)))*100.0\n",
    "\n",
    "def loadDataset(filename, split, trainingset, testset, remAttribute, whichAttribute):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        whichAttribute.append(dataset[0][remAttribute+2])\n",
    "        del dataset[0]\n",
    "        for z in range(len(dataset)):\n",
    "            del dataset[z][0]\n",
    "            del dataset[z][0]\n",
    "        for z in range(len(dataset)):\n",
    "            del dataset[z][remAttribute]\n",
    "        for x in range(1, len(dataset)-2):\n",
    "            for y in range(0, len(dataset[0])):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "            if random.random() < split:\n",
    "                trainingset.append(dataset[x])\n",
    "            else:\n",
    "                testset.append(dataset[x])\n",
    "                \n",
    "def main(remAttribute, dictionary):\n",
    "    trainingset = []\n",
    "    testset = []\n",
    "    split = 0.9\n",
    "    whichAttribute = []\n",
    "    loadDataset('datatraining.txt', split, trainingset, testset, remAttribute, whichAttribute)\n",
    "    predictions = []\n",
    "    k = 3\n",
    "    for x in range(len(testset)):\n",
    "        neighbors = getNeighbors(trainingset, testset[x], k)\n",
    "        result = getresponse(neighbors)\n",
    "        predictions.append(result)\n",
    "#        print('Predictions:' + str(result) + 'Actual:' + str(testset[x][-1]))\n",
    "    accuracy = getaccuracy(testset, predictions)\n",
    "#    print('Accuracy:' + str(accuracy) + '%')\n",
    "    dictionary[whichAttribute[0]] = float(accuracy)\n",
    "\n",
    "newAccuracies = {}\n",
    "for x in range(0,4):\n",
    "    main(x, newAccuracies)\n",
    "\n",
    "print(newAccuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "There are two questions in the portion of this lab: can attributes be removed without dropping the accuracy percentage below 90% and which attribute is the most important. I decided that because no details were given about the room (e.g whether it is a bedroom or an office), the date and time would be nonfactors in determining the occupancy of the room. In fact, my code removes these two columns of data in this question and the preceding question due to their irrelevance to the results. Therefore, the four attributes I tested removing were humidity, CO2, humidity ratio, and light. To test the accuracy without each of these attributes, I had the function \"loadDataset\" remove a certain column of data depending on the inputted attribute which was determined through the for loop that actually ran main(). Using a dictionary (printed above), I can see the accuracies of the algorithm when each attribute was removed. It can be concluded that the attribute that causes the accuracy to lower the most will be the most important attribute as it is clearly fundamental to the accuracy of the algorithm. It is important to note that I copied the whole algorithm here simply because it was hard to keep track of which functions I was changing and wanted to ensure accurate results.\n",
    "\n",
    "I found that no attribute is more important than the others. There was no attribute that I removed that affected the accuracy of the algorithm more than any of the others. After a number of tests, there was no clear trend indicating one was the most important. One interesting trend was that removing light consistently affected the algorithm's accuracy the least. What this means is that removing any one of these attributes does not really affect the accuracy of the algorithm but when looking at the attributes, light is the least important. This is likely because every time you remove one attribute, the remaining three attributes are good enough to make up for the lack of the missing one. Because no one attribute is more important than the others, removing any one attribute does not make a considerable difference to the accuracy. In fact, the lowest accuracy I saw from all of my test only decreased the accuracy by a mere 3% from a general average of 98.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
